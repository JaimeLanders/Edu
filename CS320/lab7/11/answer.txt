What I noticed during this experiment is that when I use java or c++ with the
-O0 optimization flag and pass in an argument of a = 2000000000, I get:

    2000000000 > -294967296

Where if I use the -02 optimization flag with gcc for C++ I get:

    2000000000 <= -294967296

What is happening is that when I pass in a the above value for a, the programs
are adding it to b which is:

    b = a + 2000000000 => b = 2000000000 + 2000000000 = 4000000000
	
Since the range for a signed 32 bit integer in Java and C++ is:

    [-2147483648; 2147483647]
	
	and...
	
	4000000000 !E [-2147483648; 2147483647] (!E = not an element of...)
	
The value for b is outside of this range and thus we have a signed integer
overflow which is determined by Java (and C++ with -O0 flag) to be a negative
number (overflow is ignored), hence the first output on line 4 above.  Essen-
tially Java and C++ when compiled with GCC -O0 treat the undefined behavior of
an signed integer overflow as a negative number, which is why it outputs that
a > b, where b is actually 4000000000, which clearly isn't actually the case.

However, when we compile the C++ version with GCC -O2 which is a higher level
of optimization, C++ recognized the undefined behavior as it actually is, a
number outside the range of positive values and should be treated as such with
the output of a <= b, even though it still prints b as a negative number as in
Java and C++ using gcc -O0, it knows that in this case b is actually greater
than or equal to a which is true.   
